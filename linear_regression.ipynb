{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lr(X, y):\n",
    "    X_aug = np.c_[np.ones(len(X)), X] # [X_aug] = [1, X]  -> shape: (n, 1 + d)\n",
    "    beta = np.linalg.inv(X_aug.T @ X_aug) @ (X_aug.T @ y)     # ((1+d) x (1+d))^{-1} @ (1+d, k)\n",
    "    W, b = beta[1:], beta[1]\n",
    "    return W, b\n",
    "\n",
    "def fit_lr_sgd(X, y, lr=0.01, epochs=1000, batch_size=32, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    n, d = X.shape\n",
    "    W, b = np.random.randn(d), np.random.randn()\n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.permutation(n)\n",
    "        for start in range(0, n, batch_size):\n",
    "            X_batch = X[idx[start:start+batch_size]]\n",
    "            y_batch = y[idx[start:start+batch_size]]\n",
    "\n",
    "            y_hat = X_batch @ W + b\n",
    "\n",
    "            err = y_hat - y_batch\n",
    "\n",
    "            m = len(X_batch)\n",
    "            grad_W = X_batch.T @ err / m\n",
    "            grad_b = np.sum(err) / m\n",
    "\n",
    "            W -= lr * grad_W\n",
    "            b -= lr * grad_b\n",
    "    return W, b\n",
    "\n",
    "\n",
    "def predict_lr(X, W, b):\n",
    "    return X @ W + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal  -> W: [ 1.96790081 -0.98838336] b: 1.9679008071430562\n",
      "sgd    -> W: [ 1.96707982 -0.99039957] b: 2.9780327763812835\n",
      "||W1-W2||: 0.002176954686210135 | b diff |: 1.0101319692382273\n"
     ]
    }
   ],
   "source": [
    "# Synthetic data: y = 3 + 2*x1 - x2 + noise\n",
    "rng = np.random.default_rng(42)\n",
    "X = rng.normal(size=(300, 2))\n",
    "true_W = np.array([2.0, -1.0])\n",
    "true_b = 3.0\n",
    "y = X @ true_W + true_b + rng.normal(scale=0.3, size=300)\n",
    "\n",
    "# normal\n",
    "W1, b1 = fit_lr(X, y)\n",
    "print(\"normal  -> W:\", W1, \"b:\", b1)\n",
    "\n",
    "# sgd\n",
    "W2, b2 = fit_lr_sgd(X, y, lr=0.05, epochs=200, batch_size=64)\n",
    "print(\"sgd    -> W:\", W2, \"b:\", b2)\n",
    "\n",
    "# quick check\n",
    "from numpy.linalg import norm\n",
    "print(\"||W1-W2||:\", norm(W1 - W2), \"| b diff |:\", abs(b1 - b2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
