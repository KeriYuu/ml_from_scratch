{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1573da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Very simple tokenizer:\n",
    "    - lowercases text\n",
    "    - splits on whitespace\n",
    "    \"\"\"\n",
    "    return text.lower().split()\n",
    "\n",
    "\n",
    "def build_vocab(tokenized_docs):\n",
    "    \"\"\"\n",
    "    Build a vocabulary (list of unique terms) from all documents.\n",
    "    Returns:\n",
    "      - vocab: list of terms\n",
    "      - term_index: dict mapping term -> column index\n",
    "    \"\"\"\n",
    "    all_terms = set()\n",
    "    for doc in tokenized_docs:\n",
    "        all_terms.update(doc)  # add all tokens from this doc\n",
    "    \n",
    "    vocab = sorted(all_terms)  # sorted just to be deterministic\n",
    "    term_index = {term: i for i, term in enumerate(vocab)}\n",
    "    return vocab, term_index\n",
    "\n",
    "\n",
    "def compute_tf_idf(corpus):\n",
    "    \"\"\"\n",
    "    Manually compute TF-IDF\n",
    "    Returns:\n",
    "      - tf_idf: 2D numpy array of shape (n_docs, n_terms)\n",
    "      - vocab: list of terms corresponding to columns of tf_idf\n",
    "    \"\"\"\n",
    "    # 1. Tokenize each document\n",
    "    tokenized_docs = [tokenize(doc) for doc in corpus]\n",
    "\n",
    "    # 2. Build vocabulary and term -> index mapping\n",
    "    vocab, term_index = build_vocab(tokenized_docs)\n",
    "\n",
    "    n_docs = len(corpus)\n",
    "    n_terms = len(vocab)\n",
    "\n",
    "    # 3. Build raw term-count matrix (documents x terms)\n",
    "    #    counts[d, t] = how many times term t appears in document d\n",
    "    counts = np.zeros((n_docs, n_terms), dtype=np.float64)\n",
    "\n",
    "    for d, doc in enumerate(tokenized_docs):\n",
    "        for term in doc:\n",
    "            t = term_index[term]\n",
    "            counts[d, t] += 1\n",
    "\n",
    "    # 4. Compute Term Frequency (TF)\n",
    "    #    TF(d, t) = count(d, t) / sum_t' count(d, t')\n",
    "    doc_lengths = counts.sum(axis=1, keepdims=True)  # shape (n_docs, 1)\n",
    "\n",
    "    # Avoid division by zero for empty documents using 'where' parameter\n",
    "    tf = np.divide(counts, doc_lengths, where=doc_lengths != 0)\n",
    "\n",
    "    # 5. Compute Document Frequency (DF) for each term\n",
    "    #    DF(t) = number of documents where term t appears at least once\n",
    "    df = np.count_nonzero(counts > 0, axis=0)  # shape (n_terms,)\n",
    "\n",
    "    # 6. Compute Inverse Document Frequency (IDF)\n",
    "    #    IDF(t) = 1 + log( (1 + N) / (1 + DF(t)) )\n",
    "    #    We add 1 to avoid division by zero and log(0)\n",
    "    idf = 1.0 + np.log((1.0 + n_docs) / (1.0 + df))\n",
    "\n",
    "    # 7. Combine TF and IDF\n",
    "    #    TF-IDF(d, t) = TF(d, t) * IDF(t)\n",
    "    #    Broadcasting: idf has shape (n_terms,), will be applied to each row.\n",
    "    tf_idf = tf * idf\n",
    "\n",
    "    return tf_idf, vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043e9b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (columns):\n",
      "['a', 'another', 'example', 'is', 'more', 'one', 'sample', 'this']\n",
      "\n",
      "TF-IDF matrix (rows = docs, cols = terms):\n",
      "[[0.4232868  0.         0.         0.32192052 0.         0.\n",
      "  0.32192052 0.32192052]\n",
      " [0.         0.33862944 0.51507283 0.25753641 0.         0.\n",
      "  0.         0.25753641]\n",
      " [0.         0.         0.32192052 0.         0.4232868  0.4232868\n",
      "  0.32192052 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"this is a sample\",\n",
    "    \"this is another example example\",\n",
    "    \"one more sample example\"\n",
    "]\n",
    "\n",
    "tf_idf_matrix, vocabulary = compute_tf_idf(corpus)\n",
    "\n",
    "print(\"Vocabulary (columns):\")\n",
    "print(vocabulary)\n",
    "print(\"\\nTF-IDF matrix (rows = docs, cols = terms):\")\n",
    "print(tf_idf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
